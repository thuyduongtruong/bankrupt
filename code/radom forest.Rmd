---
title: "model for bankruptcy"
author: "Duong-Trung"
date: "17/7/2020"
output: html_document
---

```{r setup, include=FALSE}
setwd("D:/Thuy Duong/R/VBM-lecture/bankruptcy paper")
library(readxl)
#Dữ liệu
data <-read_excel("dataedited.xlsx")
#str(data)
```





```{r pressure, echo=FALSE}
data$X1<-as.numeric(data$X1)
data$X2<-as.numeric(data$X2)
data$X3<-as.numeric(data$X3)
data$X4<-as.numeric(data$X4)
data$X5<-as.numeric(data$X5)
data$X6<-as.numeric(data$X6)
data$X7<-as.numeric(data$X7)
data$X8<-as.numeric(data$X8)
data$X9<-as.numeric(data$X9)
data$X10<-as.numeric(data$X10)
data$X11<-as.numeric(data$X11)
data$X12<-as.numeric(data$X12)
data$X13<-as.numeric(data$X13)
data$X14<-as.numeric(data$X14)
data$X15<-as.numeric(data$X15)
data$X16<-as.numeric(data$X16)
data$X17<-as.numeric(data$X17)
data$X18<-as.numeric(data$X18)
data$X19<-as.numeric(data$X19)
data$X20<-as.numeric(data$X20)
data$X21<-as.numeric(data$X21)
data$X22<-as.numeric(data$X22)
data$X23<-as.numeric(data$X23)
data$X24<-as.numeric(data$X24)
data$X25<-as.numeric(data$X25)
data$X26<-as.numeric(data$X26)
data$X27<-as.numeric(data$X27)
data$X28<-as.numeric(data$X28)
data$X29<-as.numeric(data$X29)
data$X30<-as.numeric(data$X30)
data$X31<-as.numeric(data$X31)

```

#
```{r}

#data <- data[!(is.na(data$Status)),]
data$status <-as.factor(data$Status)
#summary(data)
```
#Library, chia data
```{r}
library(ggplot2)
library(ModelGood)
library(VIF)
library(InformationValue)
library(lmtest)
library(survey)
library(data.table)

library(e1071)

library(caret)
library(DMwR)
library(ROSE)

# Training and testing
set.seed(1234)
ind <- sample(2, nrow(data), replace = TRUE, prob = c(0.7, 0.3))
train.d <- data [ind == 1, ]
test.d <- data [ind == 2, ]
# Check bankrupt and nonbankrupt ratio
#prop.table(table(train.d$status))
#prop.table(table(test.d$sta))
table(train.d$Status)
table(test.d$Status)


```




# Random forest full bien
```{r}
library(randomForest)





# Lựa chọn parameter
#ntree: số tree
#mtry: só variable sẽ lấy trong mỗi lần split
model2 <- randomForest(Status ~ X1+X2+X3+X4+X5+ X6+ X7+ X8 +X9+ X10 +X11+ X12 +X13+ X14+ X15+ X16+ X17 +X18+ X19+ X20 +X21+ X22+ X23+ X24+ X25+ X26+ X27+ X28+ X29+ X30+ X31, data = train.d, ntree = 500, mtry = 6, importance = TRUE)
model2





#model tuning
#install.packages("caret") # dung de xac dinh hyper parameter
library(caret)
#install.packages("e1071")
library(e1071)
#Create control function for training with 10 folds and keep 3 folds for training. search method is grid.
control <- trainControl(method='repeatedcv', 
                        number=10, # so folds
                        repeats=3, # 3 fold cho tap test
                        search='grid')
#create tunegrid with 15 values from 1:15 for mtry to tunning model. Our train function will change number of entry variable at each split according to tunegrid. 
tunegrid <- expand.grid(.mtry = (1:10)) 

rf_gridsearch <- train(Status ~ X1+X2+X3+X4+X5+ X6+ X7+ X8 +X9+ X10 +X11+ X12 +X13+ X14+ X15+ X16+ X17 +X18+ X19+ X20 +X21+ X22+ X23+ X24+ X25+ X26+ X27+ X28+ X29+ X30+ X31, 
                       data = train.d,
                       method = 'rf', # rf la random forest
                       metric = 'Accuracy',
                       tuneGrid = tunegrid)
print(rf_gridsearch) # sau khi tim dc mtry thay lai vao mo hinh de du bao


```

# chay lai random forest full bien sau khi da turning
```{r}
library(randomForest)


# Lựa chọn parameter
#ntree: số tree
#mtry: só variable sẽ lấy trong mỗi lần split
model2 <- randomForest(Status ~ X1+X2+X3+X4+X5+ X6+ X7+ X8 +X9+ X10 +X11+ X12 +X13+ X14+ X15+ X16+ X17 +X18+ X19+ X20 +X21+ X22+ X23+ X24+ X25+ X26+ X27+ X28+ X29+ X30+ X31, data =train.d, ntree = 500, mtry = 1, importance = TRUE)
model2
# Ktra dự báo trên tập train
predTrain <- predict(model2, train.d, type = "class")
table(predTrain, train.d$Status)  # ket qua 100% ACC

 
# ktra dự báo trên tập validation
predValid <- predict(model2, test.d, type = "class")
mean(predValid == test.d$status)  # mo hinh bi overfit do ACC =0.6                  
table(predValid,test.d$Status)

#variable importance
varImpPlot(model2)




```

# random forest voi lasso
```{r}

library(randomForest)
# Lựa chọn parameter
#ntree: số tree
#mtry: só variable sẽ lấy trong mỗi lần split
model2 <- randomForest(Status ~ X5+ X7 + X15+X21+ X28, data = train.d, ntree = 500, mtry = 6, importance = TRUE)
model2


#model tuning
#install.packages("caret") # dung de xac dinh hyper parameter
library(caret)
#install.packages("e1071")
#library(e1071)
#Create control function for training with 10 folds and keep 3 folds for training. search method is grid.
control <- trainControl(method='repeatedcv', 
                        number=10, # so folds
                        repeats=3, # 3 fold cho tap test
                        search='grid')
#create tunegrid with 15 values from 1:15 for mtry to tunning model. Our train function will change number of entry variable at each split according to tunegrid. 
tunegrid <- expand.grid(.mtry = (1:10)) 

rf_gridsearch <- train(Status ~ X5+  X7 + X15+X21+ X28, 
                       data = train.d,
                       method = 'rf', # rf la random forest
                       metric = 'Accuracy',
                       tuneGrid = tunegrid)
print(rf_gridsearch) # sau khi tim dc mtry thay lai vao mo hinh de du bao
```
# chay random forest voi lsso sau khi mtry
```{r}

library(randomForest)


# Lựa chọn parameter
#ntree: số tree
#mtry: só variable sẽ lấy trong mỗi lần split
model2 <- randomForest(Status ~ X5+  X7 + X15+X21+ X28, data = train.d, ntree = 500, mtry = 2, importance = TRUE)
model2
# Ktra dự báo trên tập train
predTrain <- predict(model2,train.d, type = "class")
table(predTrain, train.d$Status)  # ket qua 100% ACC

 
# ktra dự báo trên tập validation
predValid <- predict(model2, test.d, type = "class")
mean(predValid == test.d$Status) 
table(predValid,test.d$Status)

#variable importance
varImpPlot(model2)


```


